# PyBCI Examples

This folder holds multiple scripts illustrating the functions and configurations available within the PyBCI package.

NOTE:    The examples have shields describing whether they work with PyBCI's pseudoDevice class and what additional external hardware is required. If using your own LSL-capable hardware  and marker stream set `createPseudoDevice=False` or optionally pass `True` or `False` as an arguement to each script.

PyBCI requires an LSL marker stream for defining when time series data should be attributed to an action/marker/epoch and an LSL data stream to create time-series data. 

If the user has no available LSL hardware to hand they can set `createPseudoDevice=True` when instantiating the PyBCI object to enable a pseudo LSL data stream to generate time-series data and LSL marker stream for epoching the data. More information on PyBCI's Pseudo Device class can be found here: :ref:`what-pseudo-device`. 

The (example scripts)[https://pybci.readthedocs.io/en/latest/BackgroundInformation/Examples.html] illustrate various applied ML libraries (SKLearn, Tensorflow, PyTorch) or provide examples of how to integrate LSL hardware.

The code snippet can be used below to run a simple classification task using the Pseudo Device, alternatively call pybci in the command line to get a list of CLI commands and tests:


| Example File | Description |
|--------------|-------------|
| [ArduinoHandGrasp/](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/ArduinoHandGrasp/) <br> ![pseudo device not available shield](https://img.shields.io/badge/Pseudo_Device-Not_Available-blue) ![arduino required shield](https://img.shields.io/badge/Arduino-Required-blue) ![Myoware required shield](https://img.shields.io/badge/Myoware_Muscle_Sensor-Required-blue) | Folder contains an LSL marker creator in [MarkerMaker.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/ArduinoHandGrasp/MarkerMaker.py) using PyQt5 as an on screen text stimulus, illustrates how LSL markers can be used to train. [ServoControl.ino](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/ArduinoHandGrasp/ServoControl/ServoControl.ino) is designed for an arduino uno which controls 5 servo motors, each of which control the position of an indidividual finger for a 3D printed hand which can be controlled via serial commands. There is also a [Myoware Muscle Sensor](https://myoware.com/products/muscle-sensor/) attached to analog pin A0 being read continuously over the serial connection. [ArduinoToLSL.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/ArduinoHandGrasp/ArduinoToLSL.py) is used to send and receive serial data to and from the arduino, whilst pushing the A0 data to an LSL outlet which is classified in [testArduinoHand.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/ArduinoHandGrasp/testArduinoHand.py), whilst simultaneously receiving a marker stream from testArduinoHand.py to inform which hand position to do.|
| [MultimodalPupilLabsEEG/](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/MultimodalPupilLabsEEG) <br> ![pseudo device not available shield](https://img.shields.io/badge/Pseudo_Device-Not_Available-blue) ![pupil required shield](https://img.shields.io/badge/Pupil_Labs_Hardware-Required-blue) ![iobio EEG device required shield](https://img.shields.io/badge/ioBio_EEG_Device-Required-blue) | Advanced example illustrating two devices, pupil labs gaze device stream wth custom feature extractor class and Hull University ioBio EEG device, specifically channels Fp1 and Fp2. The PupilLabsRightLeftEyeClose folder has a youtube video illustrating the multimodal example in action. |
| [PupilLabsRightLeftEyeClose/](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/PupilLabsRightLeftEyeClose/) <br> ![pseudo device not available shield](https://img.shields.io/badge/Pseudo_Device-Not_Available-blue) ![pupil required shield](https://img.shields.io/badge/Pupil_Labs_Hardware-Required-blue) | Folder contains example basic pupil labs example as LSL input device, classifying left and right eye closed with a custom extractor class. RightLeftMarkers.py uses tkinter to generate visual on-screen stimuli for only right, left or both eyes open, sends same onscreen stimuli as LSL markers, ideal for testing pupil-labs eyes classifier test. bciGazeExample.py Illustrates how a 'simple' custom pupil-labs feature extractor class can be passed for the gaze data, where the mean pupil diameter is taken for each eye and both eyes and used as feature data, where nans for no confidence are set to a value of 0. |
| [testEpochTimingsConfig.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/testEpochTimingsConfig.py) <br> ![pseudo device available shield](https://img.shields.io/badge/Pseudo_Device-Available-blue) | Simple example showing custom global epoch settings  changed on initialisation. Instead of epoching data from 0 to 1 second after the marker we take it from 0.5 seconds before to 0.5 seconds after the marker. |
| [testPytorch.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/testPytorch.py) <br> ![pseudo device available shield](https://img.shields.io/badge/Pseudo_Device-Available-blue) | Provides an example of how to use a Pytorch Neural net Model as the classifier. (testRaw.py also has a Pytorch example with a C-NN). |
| [testRaw.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/testRaw.py) <br> ![pseudo device available shield](https://img.shields.io/badge/Pseudo_Device-Available-blue) | This example shows how raw time series across multiple channels can be used as an input by utilising a custom feature extractor class, combined with a custom C-NN Pytorch model when initialising PyBCI. The raw data from the data receiver thread comes in the form [samples, channels], the data receiver threads slice data based on relative timestamps meaning depending on the devices frequency for pushing LSL chunks can vary the number of samples received in the buffer for each window, to mitigate this a desired length is set and data should be trimmed based on the expected data for the created model. Multiple channels are also dropped (with the PsuedoLSLSreamGenerator in mind) to save computational complexity as raw time series over large windows can give a lot of parameters for the neural net to train.|
| [testSimple.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/testSimple.py) <br> ![pseudo device available shield](https://img.shields.io/badge/Pseudo_Device-Available-blue) | Provides the simplest setup, where no specific streams or epoch settings are given, all default to sklearn SVM classifier and GeneralEpochSettings. |
| [testSklearn.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/testSklearn.py) <br> ![pseudo device available shield](https://img.shields.io/badge/Pseudo_Device-Available-blue) | Similar to testSimple.py, but allows a custom sklearn classifier to be used. It sets individual time windows and configures data stream channels, epoch window settings, and machine learning settings before connecting to BCI and switching between training and test modes. |
| [testTensorflow.py](https://github.com/LMBooth/pybci/blob/main/pybci/Examples/testTensorflow.py) <br> ![pseudo device available shield](https://img.shields.io/badge/Pseudo_Device-Available-blue) | Similar to testSimple.py, but allows for a custom TensorFlow model to be used. It establishes a connection to BCI, starts training on received epochs, checks the classifier's accuracy, and then switches to test mode to predict the current marker. |

